{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "niftynet_path = '/home/tom/phd/NiftyNet-Generator-PR/NiftyNet'\n",
    "sys.path.append(niftynet_path)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from niftynet.io.image_reader import ImageReader\n",
    "from niftynet.io.image_sets_partitioner import ImageSetsPartitioner\n",
    "from collections import namedtuple\n",
    "\n",
    "from niftynet.contrib.preprocessors.preprocessing import Preprocessing\n",
    "from niftynet.contrib.csv_reader.sampler_csv_rows import ImageWindowDatasetCSV\n",
    "from niftynet.contrib.csv_reader.sampler_resize_v2_csv import ResizeSamplerCSV as ResizeSampler\n",
    "from niftynet.contrib.csv_reader.csv_reader import CSVReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Some setup\n",
    "NetParam = namedtuple('NetParam', 'normalise_foreground_only foreground_type multimod_foreground_type histogram_ref_file norm_type cutoff normalisation whitening')\n",
    "ActionParam = namedtuple('ActionParam', 'random_flipping_axes scaling_percentage rotation_angle rotation_angle_x rotation_angle_y rotation_angle_z do_elastic_deformation num_ctrl_points deformation_sigma proportion_to_deform')\n",
    "class TaskParam:\n",
    "    def __init__(self, classes):\n",
    "        self.image = classes\n",
    "net_param = NetParam(normalise_foreground_only=False, foreground_type='threshold_plus', multimod_foreground_type = 'and', histogram_ref_file='mapping.txt', norm_type='percentile', cutoff=(0.05, 0.95), normalisation=False, whitening=True)\n",
    "action_param = ActionParam(random_flipping_axes=[], scaling_percentage=[], rotation_angle=None, rotation_angle_x=None, rotation_angle_y=None, rotation_angle_z=None, do_elastic_deformation=False, num_ctrl_points=6, deformation_sigma=50, proportion_to_deform=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Create a csv of labels and show how it can be returned by the CSV Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from niftynet.utilities.download import download\n",
    "download('mr_ct_regression_model_zoo_data')\n",
    "labels_location = 'ct.csv'\n",
    "files = [file for file in os.listdir('/home/tom/niftynet/data/mr_ct_regression/CT_zero_mean') if file.endswith('.nii.gz')]\n",
    "pd.DataFrame(data=[(file.replace('.nii.gz', ''), file.replace('.nii.gz', '')) for file in files]).to_csv('label.csv', index=None, header=['subject_id', 'label'])\n",
    "pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing the CSV Reader on labels\n",
    "# Make sure we accept 'Label', 'label', 'LABEL'\n",
    "task_param = TaskParam(['image'])\n",
    "image_data_param = {'CT': {'path_to_search': '~/niftynet/data/mr_ct_regression/CT_zero_mean', 'filename_contains': 'nii'}}\n",
    "#Â Change csv_file -> csv_path_file, csv_data_file is a csv with data\n",
    "csv_data_param = {'label': {'csv_data_file': 'label.csv', 'to_ohe': True}}\n",
    "grouping_param = {'image': (['CT'])}\n",
    "\n",
    "image_sets_partitioner = ImageSetsPartitioner().initialise(image_data_param)\n",
    "image_reader = ImageReader().initialise(image_data_param, grouping_param, file_list=image_sets_partitioner.all_files)\n",
    "preprocessing = Preprocessing(net_param, action_param, task_param)\n",
    "normalisation_layers = preprocessing.prepare_normalisation_layers()\n",
    "augmentation_layers = preprocessing.prepare_augmentation_layers()\n",
    "image_reader.add_preprocessing_layers(normalisation_layers + augmentation_layers)\n",
    "csv_reader = CSVReader().initialise(csv_data_param, 'label', file_list=image_sets_partitioner.all_files)\n",
    "print('One sample from the csv_reader:', np.squeeze(csv_reader(idx=13)[1]['label']))\n",
    "window_sizes = {'image': (100, 100, 1), 'label': (1, 1, 1)}\n",
    "sampler = ResizeSampler(reader=image_reader,\n",
    "                        csv_reader=csv_reader,\n",
    "                        window_sizes=window_sizes,\n",
    "                        num_threads=2,\n",
    "                        smaller_final_batch_mode='drop',\n",
    "                        batch_size=2,\n",
    "                        queue_length=2)\n",
    "sample = next(sampler())\n",
    "print(sample['image'].shape)\n",
    "print(sample['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create a csv of features and show how it can be returned by the CSV Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from niftynet.utilities.download import download\n",
    "download('mr_ct_regression_model_zoo_data')\n",
    "labels_location = 'ct.csv'\n",
    "files = [file.replace('.nii.gz', '') for file in os.listdir('/home/tom/niftynet/data/mr_ct_regression/CT_zero_mean') if file.endswith('.nii.gz')]\n",
    "\n",
    "pd.DataFrame(data=[tuple([file] + list(np.random.randn(10))) for file in files]).to_csv('features.csv', index=None, header=['subject_id'] + [str(x) for x in range(10)])\n",
    "pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_param = TaskParam(['image'])\n",
    "image_data_param = {'CT': {'path_to_search': '~/niftynet/data/mr_ct_regression/CT_zero_mean', 'filename_contains': 'nii'}}\n",
    "csv_data_param = {'features': {'csv_data_file': 'features.csv', 'to_ohe': False}}\n",
    "grouping_param = {'image': (['CT'])}\n",
    "image_sets_partitioner = ImageSetsPartitioner().initialise(image_data_param)\n",
    "image_reader = ImageReader().initialise(image_data_param, grouping_param, file_list=image_sets_partitioner.all_files)\n",
    "preprocessing = Preprocessing(net_param, action_param, task_param)\n",
    "normalisation_layers = preprocessing.prepare_normalisation_layers()\n",
    "augmentation_layers = preprocessing.prepare_augmentation_layers()\n",
    "image_reader.add_preprocessing_layers(normalisation_layers + augmentation_layers)\n",
    "csv_reader = CSVReader().initialise(csv_data_param, 'features', file_list=image_sets_partitioner.all_files)\n",
    "print('One sample from the csv_reader:', np.squeeze(csv_reader(idx=13)[1]['features']))\n",
    "window_sizes = {'image': (100, 100, 1), 'features': (1, 1, 1)}\n",
    "sampler = ResizeSampler(reader=image_reader,\n",
    "                        csv_reader=csv_reader,\n",
    "                        window_sizes=window_sizes,\n",
    "                        num_threads=2,\n",
    "                        smaller_final_batch_mode='drop',\n",
    "                        batch_size=2,\n",
    "                        queue_length=2)\n",
    "sample = next(sampler())\n",
    "print(sample['image'].shape)\n",
    "print(sample['features'].shape)\n",
    "print(sample.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create random patches with labels ###\n",
    "for file in os.listdir('/home/tom/niftynet/data/mr_ct_regression/CT_zero_mean'):\n",
    "    subject_id = file.replace('.nii.gz', '')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Resize input image as output window.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import tensorflow as tf\n",
    "\n",
    "from niftynet.contrib.csv_reader.sampler_csv_rows import ImageWindowDatasetCSV\n",
    "from niftynet.engine.image_window import LOCATION_FORMAT\n",
    "\n",
    "\n",
    "class PatchBasedSamplerCSV(ImageWindowDatasetCSV):\n",
    "    \"\"\"\n",
    "    This class generates samples by reading a csv file\n",
    "    with coordinates specifying where the user should\n",
    "    sample from.\n",
    "    \n",
    "    Assuming the reader's output is 5d:\n",
    "    ``Height x Width x Depth x time x Modality``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 reader,\n",
    "                 csv_reader=None,\n",
    "                 window_sizes=None,\n",
    "                 batch_size=1,\n",
    "                 spatial_window_size=None,\n",
    "                 windows_per_image=1,\n",
    "                 shuffle=True,\n",
    "                 queue_length=10,\n",
    "                 num_threads=4,\n",
    "                 smaller_final_batch_mode='pad',\n",
    "                 name='resize_sampler_v2'):\n",
    "        tf.logging.info('reading size of preprocessed images')\n",
    "        self.csv_reader = csv_reader\n",
    "        ImageWindowDatasetCSV.__init__(\n",
    "            self,\n",
    "            reader=reader,\n",
    "            csv_reader=csv_reader,\n",
    "            window_sizes=window_sizes,\n",
    "            batch_size=batch_size,\n",
    "            windows_per_image=windows_per_image,\n",
    "            queue_length=queue_length,\n",
    "            num_threads=num_threads,\n",
    "            shuffle=shuffle,\n",
    "            epoch=-1 if shuffle else 1,\n",
    "            smaller_final_batch_mode=smaller_final_batch_mode,\n",
    "            name=name)\n",
    "        if spatial_window_size:\n",
    "            # override all spatial window defined in input\n",
    "            # modalities sections\n",
    "            # this is useful when do inference with a spatial window\n",
    "            # which is different from the training specifications\n",
    "            self.window.set_spatial_shape(spatial_window_size)\n",
    "        # tf.logging.info(\"initialised resize sampler %s \", self.window.shapes)\n",
    "        # tf.logging.info('CSV reader is {}'.format(self.csv_reader))\n",
    "\n",
    "    def layer_op(self, idx=None):\n",
    "        \"\"\"\n",
    "        This function generates sampling windows to the input buffer\n",
    "        image data are from ``self.reader()``.\n",
    "\n",
    "        It first completes window shapes based on image data,\n",
    "        then resize each image as window and output\n",
    "        a dictionary (required by input buffer)\n",
    "\n",
    "        :return: output data dictionary ``{'image_modality': data_array}``\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            image_id, data, interp_orders = self.reader(idx=idx)\n",
    "            image_shapes = \\\n",
    "                dict((name, data[name].shape) for name in self.window.names)\n",
    "            # window shapes can be dynamic, here they\n",
    "            # are converted to static ones\n",
    "            # as now we know the image shapes\n",
    "            static_window_shapes = self.window.match_image_shapes(image_shapes)\n",
    "\n",
    "            # for resize sampler the coordinates are not used\n",
    "            # simply use the spatial dims of the input image\n",
    "            output_dict = {}\n",
    "            for name in list(data):\n",
    "                # prepare output dictionary keys\n",
    "                coordinates_key = LOCATION_FORMAT.format(name)\n",
    "                image_data_key = name\n",
    "\n",
    "                output_dict[coordinates_key] = self.dummy_coordinates(\n",
    "                    image_id, static_window_shapes[name], self.window.n_samples)\n",
    "                image_array = []\n",
    "                for _ in range(self.window.n_samples):\n",
    "                    # prepare image data\n",
    "                    image_shape = image_shapes[name]\n",
    "                    window_shape = static_window_shapes[name]\n",
    "\n",
    "                    if image_shape == window_shape or interp_orders[name][0] < 0:\n",
    "                        # already in the same shape\n",
    "                        image_window = data[name]\n",
    "                    else:\n",
    "                        zoom_ratio = [float(p) / float(d) for p, d in\n",
    "                                      zip(window_shape, image_shape)]\n",
    "                        image_window = zoom_3d(image=data[name],\n",
    "                                               ratio=zoom_ratio, interp_order=\n",
    "                                               interp_orders[name][0])\n",
    "                    image_array.append(image_window[np.newaxis, ...])\n",
    "                if len(image_array) > 1:\n",
    "                    output_dict[image_data_key] = \\\n",
    "                        np.concatenate(image_array, axis=0)\n",
    "                else:\n",
    "                    output_dict[image_data_key] = image_array[0]\n",
    "            # the output image shape should be\n",
    "            # [enqueue_batch_size, x, y, z, time, modality]\n",
    "            # here enqueue_batch_size = 1 as we only have one sample\n",
    "            # per image\n",
    "            if self.csv_reader is not None:\n",
    "                _, label_dict, _ = self.csv_reader(idx=image_id)\n",
    "                output_dict['label'] = label_dict['label']\n",
    "                output_dict['label_location'] = output_dict['image_location']\n",
    "            yield output_dict\n",
    "\n",
    "\n",
    "def zoom_3d(image, ratio, interp_order):\n",
    "    \"\"\"\n",
    "    Taking 5D image as input, and zoom each 3D slice independently\n",
    "    \"\"\"\n",
    "    assert image.ndim == 5, \"input images should be 5D array\"\n",
    "    output = []\n",
    "    for time_pt in range(image.shape[3]):\n",
    "        output_mod = []\n",
    "        for mod in range(image.shape[4]):\n",
    "            zoomed = scipy.ndimage.zoom(\n",
    "                image[..., time_pt, mod], ratio[:3], order=interp_order)\n",
    "            output_mod.append(zoomed[..., np.newaxis, np.newaxis])\n",
    "        output.append(np.concatenate(output_mod, axis=-1))\n",
    "    return np.concatenate(output, axis=-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_parallel_calls = [2, 4, 8, 16]\n",
    "print(num_parallel_calls)\n",
    "total_times_dict = {}\n",
    "batches = 10\n",
    "batch_size = 100\n",
    "for num_parallel_call in num_parallel_calls:\n",
    "    window_sizes = {'image': (100, 100, 100), 'label': (1, 1, 1)}\n",
    "    sampler = ResizeSampler(reader=image_reader,\n",
    "                            csv_reader=csv_reader,\n",
    "                            window_sizes=window_sizes,\n",
    "                            num_threads=num_parallel_call,\n",
    "                            smaller_final_batch_mode='drop',\n",
    "                            batch_size=batch_size,\n",
    "                            queue_length=num_parallel_call)\n",
    "    next_window = sampler.pop_batch_op()\n",
    "    with tf.Session() as sess:\n",
    "        print('Num Parallel Calls: {}'.format(num_parallel_call))\n",
    "        t0 = time.time()\n",
    "        batch_times = []\n",
    "        sess.run(sampler.iterator.make_initializer(sampler.dataset))\n",
    "        for i in range(batches):\n",
    "            try:\n",
    "                value = sess.run(next_window)\n",
    "                print(value['image'].shape, value['label'].shape)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            batch_time = time.time() - t0\n",
    "            batch_times.append(batch_time)\n",
    "            print('Batch {} / {}'.format(i+1, batches))\n",
    "            print('Time per batch: {}'.format(batch_time))\n",
    "            t0 = time.time()\n",
    "        total_times_dict[num_parallel_call] = batch_times\n",
    "        print('Mean batch time: {}'.format(sum(batch_times[1:])/len(batch_times[1:])))\n",
    "    if sampler._enqueuer is not None:\n",
    "        sampler._enqueuer.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "to_plot = [2, 4, 8, 16]\n",
    "means = [np.mean(total_times_dict[num][1:]) for num in to_plot]\n",
    "ideal = [np.mean(total_times_dict[num][1:]) * 2 / num for num in to_plot]\n",
    "plt.plot(to_plot, means, label='observed')\n",
    "plt.plot(to_plot, ideal, label='ideal')\n",
    "plt.title('Mean time per image as threads increases for 80 thread machine')\n",
    "plt.xlabel('Threads')\n",
    "plt.ylabel('mean time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=([(1, 0, 1, 0, 0) for _ in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
