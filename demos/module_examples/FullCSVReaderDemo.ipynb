{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow version 1.10.0\n",
      "CRITICAL:tensorflow:Optional Python module SimpleITK not found, please install SimpleITK and retry if the application fails.\n",
      "INFO:tensorflow:Available Image Loaders:\n",
      "['nibabel', 'opencv', 'skimage', 'pillow', 'dummy'].\n",
      "\u001b[1mINFO:niftynet:\u001b[0m Optional Python module SimpleITK not found, please install SimpleITK and retry if the application fails.\n",
      "\u001b[1mINFO:niftynet:\u001b[0m Optional Python module SimpleITK version None not found, please install SimpleITK-None and retry if the application fails.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "niftynet_path = '/home/tom/phd/NiftyNet-Generator-PR/NiftyNet'\n",
    "sys.path.append(niftynet_path)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from niftynet.io.image_reader import ImageReader\n",
    "from niftynet.io.image_sets_partitioner import ImageSetsPartitioner\n",
    "from collections import namedtuple\n",
    "\n",
    "from niftynet.contrib.preprocessors.preprocessing import Preprocessing\n",
    "from niftynet.contrib.csv_reader.sampler_csv_rows import ImageWindowDatasetCSV\n",
    "from niftynet.contrib.csv_reader.sampler_resize_v2_csv import ResizeSamplerCSV as ResizeSampler\n",
    "from niftynet.contrib.csv_reader.csv_reader import CSVReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Some setup\n",
    "NetParam = namedtuple('NetParam', 'normalise_foreground_only foreground_type multimod_foreground_type histogram_ref_file norm_type cutoff normalisation whitening')\n",
    "ActionParam = namedtuple('ActionParam', 'random_flipping_axes scaling_percentage rotation_angle rotation_angle_x rotation_angle_y rotation_angle_z do_elastic_deformation num_ctrl_points deformation_sigma proportion_to_deform')\n",
    "class TaskParam:\n",
    "    def __init__(self, classes):\n",
    "        self.image = classes\n",
    "net_param = NetParam(normalise_foreground_only=False, foreground_type='threshold_plus', multimod_foreground_type = 'and', histogram_ref_file='mapping.txt', norm_type='percentile', cutoff=(0.05, 0.95), normalisation=False, whitening=True)\n",
    "action_param = ActionParam(random_flipping_axes=[], scaling_percentage=[], rotation_angle=None, rotation_angle_x=None, rotation_angle_y=None, rotation_angle_z=None, do_elastic_deformation=False, num_ctrl_points=6, deformation_sigma=50, proportion_to_deform=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Create a csv of labels and show how it can be returned by the CSV Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing: https://github.com/NifTK/NiftyNetModelZoo\n",
      "mr_ct_regression_model_zoo_data: FAIL. \n",
      "No NiftyNet example was found for mr_ct_regression_model_zoo_data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAN</td>\n",
       "      <td>RAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAL</td>\n",
       "      <td>HAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIL</td>\n",
       "      <td>MIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHA</td>\n",
       "      <td>CHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRA</td>\n",
       "      <td>GRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLA</td>\n",
       "      <td>PLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAR</td>\n",
       "      <td>NAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WEB</td>\n",
       "      <td>WEB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAR</td>\n",
       "      <td>PAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HON</td>\n",
       "      <td>HON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HAF</td>\n",
       "      <td>HAF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LEW</td>\n",
       "      <td>LEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOU</td>\n",
       "      <td>SOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SPE</td>\n",
       "      <td>SPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CRI</td>\n",
       "      <td>CRI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id label\n",
       "0         RAN   RAN\n",
       "1         HAL   HAL\n",
       "2         MIL   MIL\n",
       "3         CHA   CHA\n",
       "4         GRA   GRA\n",
       "5         PLA   PLA\n",
       "6         NAR   NAR\n",
       "7         WEB   WEB\n",
       "8         PAR   PAR\n",
       "9         HON   HON\n",
       "10        HAF   HAF\n",
       "11        LEW   LEW\n",
       "12        SOU   SOU\n",
       "13        SPE   SPE\n",
       "14        CRI   CRI"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from niftynet.utilities.download import download\n",
    "download('mr_ct_regression_model_zoo_data')\n",
    "labels_location = 'ct.csv'\n",
    "files = [file for file in os.listdir('/home/tom/niftynet/data/mr_ct_regression/CT_zero_mean') if file.endswith('.nii.gz')]\n",
    "pd.DataFrame(data=[(file.replace('.nii.gz', ''), file.replace('.nii.gz', '')) for file in files]).to_csv('label.csv', index=None, header=['subject_id', 'label'])\n",
    "pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m \n",
      "\n",
      "Number of subjects 15, input section names: ['subject_id', 'CT']\n",
      "-- using all subjects (without data partitioning).\n",
      "\n",
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 15 subjects from sections ['CT'] as input [image]\n",
      "\u001b[1mWARNING:niftynet:\u001b[0m This method will read your entire csv into memory\n",
      "One sample from the csv_reader: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\u001b[1mINFO:niftynet:\u001b[0m reading size of preprocessed images\n",
      "\u001b[1mWARNING:niftynet:\u001b[0m sampler queue_length should be larger than batch_size, defaulting to batch_size * 5.0 (10).\n",
      "(1, 100, 100, 1, 1, 1)\n",
      "(1, 15, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#### Testing the CSV Reader on labels\n",
    "# Make sure we accept 'Label', 'label', 'LABEL'\n",
    "task_param = TaskParam(['image'])\n",
    "image_data_param = {'CT': {'path_to_search': '~/niftynet/data/mr_ct_regression/CT_zero_mean', 'filename_contains': 'nii'}}\n",
    "#Â Change csv_file -> csv_path_file, csv_data_file is a csv with data\n",
    "csv_data_param = {'label': {'csv_data_file': 'label.csv', 'to_ohe': True}}\n",
    "grouping_param = {'image': (['CT'])}\n",
    "\n",
    "image_sets_partitioner = ImageSetsPartitioner().initialise(image_data_param)\n",
    "image_reader = ImageReader().initialise(image_data_param, grouping_param, file_list=image_sets_partitioner.all_files)\n",
    "preprocessing = Preprocessing(net_param, action_param, task_param)\n",
    "normalisation_layers = preprocessing.prepare_normalisation_layers()\n",
    "augmentation_layers = preprocessing.prepare_augmentation_layers()\n",
    "image_reader.add_preprocessing_layers(normalisation_layers + augmentation_layers)\n",
    "csv_reader = CSVReader(('label',)).initialise(csv_data_param, {'label': (['label'])}, file_list=image_sets_partitioner.all_files)\n",
    "print('One sample from the csv_reader:', np.squeeze(csv_reader(idx=13)[1]['label']))\n",
    "window_sizes = {'image': (100, 100, 1), 'label': (1, 1, 1)}\n",
    "sampler = ResizeSampler(reader=image_reader,\n",
    "                        csv_reader=csv_reader,\n",
    "                        window_sizes=window_sizes,\n",
    "                        num_threads=2,\n",
    "                        smaller_final_batch_mode='drop',\n",
    "                        batch_size=2,\n",
    "                        queue_length=2)\n",
    "sample = next(sampler())\n",
    "print(sample['image'].shape)\n",
    "print(sample['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create a csv of features and show how it can be returned by the CSV Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing: https://github.com/NifTK/NiftyNetModelZoo\n",
      "mr_ct_regression_model_zoo_data: FAIL. \n",
      "No NiftyNet example was found for mr_ct_regression_model_zoo_data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAN</td>\n",
       "      <td>0.321972</td>\n",
       "      <td>0.652648</td>\n",
       "      <td>0.113185</td>\n",
       "      <td>-0.722681</td>\n",
       "      <td>-0.593930</td>\n",
       "      <td>-0.900718</td>\n",
       "      <td>-0.808985</td>\n",
       "      <td>-0.368086</td>\n",
       "      <td>-1.262447</td>\n",
       "      <td>-2.299978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAL</td>\n",
       "      <td>-0.439402</td>\n",
       "      <td>0.675593</td>\n",
       "      <td>-0.657466</td>\n",
       "      <td>0.768496</td>\n",
       "      <td>-0.382948</td>\n",
       "      <td>0.474596</td>\n",
       "      <td>-0.276786</td>\n",
       "      <td>-0.392421</td>\n",
       "      <td>-0.119055</td>\n",
       "      <td>1.252547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIL</td>\n",
       "      <td>1.085595</td>\n",
       "      <td>0.076346</td>\n",
       "      <td>0.345417</td>\n",
       "      <td>-0.196474</td>\n",
       "      <td>0.716523</td>\n",
       "      <td>-0.548726</td>\n",
       "      <td>0.408472</td>\n",
       "      <td>0.018024</td>\n",
       "      <td>-0.583368</td>\n",
       "      <td>-0.780949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHA</td>\n",
       "      <td>-2.210596</td>\n",
       "      <td>-0.137564</td>\n",
       "      <td>0.323351</td>\n",
       "      <td>0.891198</td>\n",
       "      <td>-0.778046</td>\n",
       "      <td>0.031523</td>\n",
       "      <td>-0.463217</td>\n",
       "      <td>-0.685250</td>\n",
       "      <td>-0.172702</td>\n",
       "      <td>0.011653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRA</td>\n",
       "      <td>0.829021</td>\n",
       "      <td>-0.344907</td>\n",
       "      <td>-1.552366</td>\n",
       "      <td>-2.156463</td>\n",
       "      <td>-0.772904</td>\n",
       "      <td>-0.023208</td>\n",
       "      <td>1.357851</td>\n",
       "      <td>0.409369</td>\n",
       "      <td>0.667640</td>\n",
       "      <td>-0.151443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLA</td>\n",
       "      <td>0.410349</td>\n",
       "      <td>1.233560</td>\n",
       "      <td>0.108877</td>\n",
       "      <td>-0.946675</td>\n",
       "      <td>0.379490</td>\n",
       "      <td>-0.195135</td>\n",
       "      <td>-0.299669</td>\n",
       "      <td>-0.072078</td>\n",
       "      <td>0.060394</td>\n",
       "      <td>0.123195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAR</td>\n",
       "      <td>0.836927</td>\n",
       "      <td>0.857035</td>\n",
       "      <td>0.874829</td>\n",
       "      <td>0.686557</td>\n",
       "      <td>-0.891095</td>\n",
       "      <td>-0.223142</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>1.012295</td>\n",
       "      <td>1.178720</td>\n",
       "      <td>-1.403227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WEB</td>\n",
       "      <td>1.330076</td>\n",
       "      <td>-1.140574</td>\n",
       "      <td>2.268951</td>\n",
       "      <td>-1.947345</td>\n",
       "      <td>-0.734009</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>-0.182076</td>\n",
       "      <td>-0.303120</td>\n",
       "      <td>1.700154</td>\n",
       "      <td>0.836683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAR</td>\n",
       "      <td>-0.861265</td>\n",
       "      <td>0.076940</td>\n",
       "      <td>1.981806</td>\n",
       "      <td>-0.018995</td>\n",
       "      <td>-0.362837</td>\n",
       "      <td>-1.420218</td>\n",
       "      <td>0.347479</td>\n",
       "      <td>-0.656022</td>\n",
       "      <td>1.957113</td>\n",
       "      <td>-0.974995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HON</td>\n",
       "      <td>-0.133184</td>\n",
       "      <td>-0.681829</td>\n",
       "      <td>0.238010</td>\n",
       "      <td>1.288651</td>\n",
       "      <td>-0.573452</td>\n",
       "      <td>2.361199</td>\n",
       "      <td>-0.795531</td>\n",
       "      <td>-1.134068</td>\n",
       "      <td>-0.439827</td>\n",
       "      <td>-0.498937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HAF</td>\n",
       "      <td>0.684381</td>\n",
       "      <td>-1.145172</td>\n",
       "      <td>-0.115175</td>\n",
       "      <td>0.446454</td>\n",
       "      <td>-0.649224</td>\n",
       "      <td>-0.882938</td>\n",
       "      <td>-0.983248</td>\n",
       "      <td>0.571107</td>\n",
       "      <td>-0.390658</td>\n",
       "      <td>0.067865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LEW</td>\n",
       "      <td>1.150170</td>\n",
       "      <td>-0.793785</td>\n",
       "      <td>0.590165</td>\n",
       "      <td>-0.126870</td>\n",
       "      <td>-0.887013</td>\n",
       "      <td>0.495526</td>\n",
       "      <td>-0.395386</td>\n",
       "      <td>0.448884</td>\n",
       "      <td>-1.646706</td>\n",
       "      <td>0.523825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOU</td>\n",
       "      <td>0.792047</td>\n",
       "      <td>-1.516437</td>\n",
       "      <td>1.087191</td>\n",
       "      <td>-3.077545</td>\n",
       "      <td>0.286219</td>\n",
       "      <td>0.756354</td>\n",
       "      <td>-0.795725</td>\n",
       "      <td>-1.012792</td>\n",
       "      <td>0.194806</td>\n",
       "      <td>-0.874716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SPE</td>\n",
       "      <td>-1.675722</td>\n",
       "      <td>-1.730294</td>\n",
       "      <td>1.013535</td>\n",
       "      <td>0.354879</td>\n",
       "      <td>-1.044123</td>\n",
       "      <td>0.656389</td>\n",
       "      <td>0.549337</td>\n",
       "      <td>-1.416101</td>\n",
       "      <td>-1.320003</td>\n",
       "      <td>-1.398806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CRI</td>\n",
       "      <td>-1.193647</td>\n",
       "      <td>1.017665</td>\n",
       "      <td>-1.156596</td>\n",
       "      <td>0.947748</td>\n",
       "      <td>-2.377250</td>\n",
       "      <td>-0.177449</td>\n",
       "      <td>0.893184</td>\n",
       "      <td>1.063577</td>\n",
       "      <td>-0.580513</td>\n",
       "      <td>-0.128269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id         0         1         2         3         4         5  \\\n",
       "0         RAN  0.321972  0.652648  0.113185 -0.722681 -0.593930 -0.900718   \n",
       "1         HAL -0.439402  0.675593 -0.657466  0.768496 -0.382948  0.474596   \n",
       "2         MIL  1.085595  0.076346  0.345417 -0.196474  0.716523 -0.548726   \n",
       "3         CHA -2.210596 -0.137564  0.323351  0.891198 -0.778046  0.031523   \n",
       "4         GRA  0.829021 -0.344907 -1.552366 -2.156463 -0.772904 -0.023208   \n",
       "5         PLA  0.410349  1.233560  0.108877 -0.946675  0.379490 -0.195135   \n",
       "6         NAR  0.836927  0.857035  0.874829  0.686557 -0.891095 -0.223142   \n",
       "7         WEB  1.330076 -1.140574  2.268951 -1.947345 -0.734009  0.002782   \n",
       "8         PAR -0.861265  0.076940  1.981806 -0.018995 -0.362837 -1.420218   \n",
       "9         HON -0.133184 -0.681829  0.238010  1.288651 -0.573452  2.361199   \n",
       "10        HAF  0.684381 -1.145172 -0.115175  0.446454 -0.649224 -0.882938   \n",
       "11        LEW  1.150170 -0.793785  0.590165 -0.126870 -0.887013  0.495526   \n",
       "12        SOU  0.792047 -1.516437  1.087191 -3.077545  0.286219  0.756354   \n",
       "13        SPE -1.675722 -1.730294  1.013535  0.354879 -1.044123  0.656389   \n",
       "14        CRI -1.193647  1.017665 -1.156596  0.947748 -2.377250 -0.177449   \n",
       "\n",
       "           6         7         8         9  \n",
       "0  -0.808985 -0.368086 -1.262447 -2.299978  \n",
       "1  -0.276786 -0.392421 -0.119055  1.252547  \n",
       "2   0.408472  0.018024 -0.583368 -0.780949  \n",
       "3  -0.463217 -0.685250 -0.172702  0.011653  \n",
       "4   1.357851  0.409369  0.667640 -0.151443  \n",
       "5  -0.299669 -0.072078  0.060394  0.123195  \n",
       "6   0.021994  1.012295  1.178720 -1.403227  \n",
       "7  -0.182076 -0.303120  1.700154  0.836683  \n",
       "8   0.347479 -0.656022  1.957113 -0.974995  \n",
       "9  -0.795531 -1.134068 -0.439827 -0.498937  \n",
       "10 -0.983248  0.571107 -0.390658  0.067865  \n",
       "11 -0.395386  0.448884 -1.646706  0.523825  \n",
       "12 -0.795725 -1.012792  0.194806 -0.874716  \n",
       "13  0.549337 -1.416101 -1.320003 -1.398806  \n",
       "14  0.893184  1.063577 -0.580513 -0.128269  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from niftynet.utilities.download import download\n",
    "download('mr_ct_regression_model_zoo_data')\n",
    "labels_location = 'ct.csv'\n",
    "files = [file.replace('.nii.gz', '') for file in os.listdir('/home/tom/niftynet/data/mr_ct_regression/CT_zero_mean') if file.endswith('.nii.gz')]\n",
    "\n",
    "pd.DataFrame(data=[tuple([file] + list(np.random.randn(10))) for file in files]).to_csv('features.csv', index=None, header=['subject_id'] + [str(x) for x in range(10)])\n",
    "pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m \n",
      "\n",
      "Number of subjects 15, input section names: ['subject_id', 'CT']\n",
      "-- using all subjects (without data partitioning).\n",
      "\n",
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 15 subjects from sections ['CT'] as input [image]\n",
      "\u001b[1mWARNING:niftynet:\u001b[0m This method will read your entire csv into memory\n",
      "One sample from the csv_reader: [-1.67572209 -1.73029411  1.01353478  0.35487928 -1.0441231   0.65638927\n",
      "  0.54933651 -1.41610099 -1.32000264 -1.39880624]\n",
      "\u001b[1mINFO:niftynet:\u001b[0m reading size of preprocessed images\n",
      "\u001b[1mWARNING:niftynet:\u001b[0m sampler queue_length should be larger than batch_size, defaulting to batch_size * 5.0 (10).\n",
      "(1, 100, 100, 1, 1, 1)\n",
      "(1, 10, 1, 1, 1, 1)\n",
      "dict_keys(['image_location', 'image', 'features', 'features_location'])\n"
     ]
    }
   ],
   "source": [
    "task_param = TaskParam(['image'])\n",
    "image_data_param = {'CT': {'path_to_search': '~/niftynet/data/mr_ct_regression/CT_zero_mean', 'filename_contains': 'nii'}}\n",
    "csv_data_param = {'features': {'csv_data_file': 'features.csv', 'to_ohe': False}}\n",
    "grouping_param = {'image': (['CT'])}\n",
    "image_sets_partitioner = ImageSetsPartitioner().initialise(image_data_param)\n",
    "image_reader = ImageReader().initialise(image_data_param, grouping_param, file_list=image_sets_partitioner.all_files)\n",
    "preprocessing = Preprocessing(net_param, action_param, task_param)\n",
    "normalisation_layers = preprocessing.prepare_normalisation_layers()\n",
    "augmentation_layers = preprocessing.prepare_augmentation_layers()\n",
    "image_reader.add_preprocessing_layers(normalisation_layers + augmentation_layers)\n",
    "csv_reader = CSVReader(('features',)).initialise(csv_data_param, {'features': ['features']}, file_list=image_sets_partitioner.all_files)\n",
    "print('One sample from the csv_reader:', np.squeeze(csv_reader(idx=13)[1]['features']))\n",
    "window_sizes = {'image': (100, 100, 1), 'features': (1, 1, 1)}\n",
    "sampler = ResizeSampler(reader=image_reader,\n",
    "                        csv_reader=csv_reader,\n",
    "                        window_sizes=window_sizes,\n",
    "                        num_threads=2,\n",
    "                        smaller_final_batch_mode='drop',\n",
    "                        batch_size=2,\n",
    "                        queue_length=2)\n",
    "sample = next(sampler())\n",
    "print(sample['image'].shape)\n",
    "print(sample['features'].shape)\n",
    "print(sample.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the CSV Reader on labels AND Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[Layer]\u001b[0m csv_reader_6 \u001b[46m(input undecided)\u001b[0m\n",
      "\u001b[1mINFO:niftynet:\u001b[0m \n",
      "\n",
      "Number of subjects 15, input section names: ['subject_id', 'CT']\n",
      "-- using all subjects (without data partitioning).\n",
      "\n",
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 15 subjects from sections ['CT'] as input [image]\n",
      "\u001b[1mWARNING:niftynet:\u001b[0m This method will read your entire csv into memory\n",
      "\u001b[1mWARNING:niftynet:\u001b[0m This method will read your entire csv into memory\n",
      "One sample from the csv_reader: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\u001b[1mINFO:niftynet:\u001b[0m reading size of preprocessed images\n",
      "\u001b[1mWARNING:niftynet:\u001b[0m sampler queue_length should be larger than batch_size, defaulting to batch_size * 5.0 (10).\n",
      "(1, 100, 100, 1, 1, 1)\n",
      "(1, 15, 1, 1, 1, 1)\n",
      "(1, 10, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make sure we accept 'Label', 'label', 'LABEL'\n",
    "task_param = TaskParam(['image'])\n",
    "image_data_param = {'CT': {'path_to_search': '~/niftynet/data/mr_ct_regression/CT_zero_mean', 'filename_contains': 'nii'}}\n",
    "csv_data_param = {'label': {'csv_data_file': 'label.csv', 'to_ohe': True},\n",
    "                  'features': {'csv_data_file': 'features.csv', 'to_ohe': False}}\n",
    "grouping_param = {'image': (['CT'])}\n",
    "\n",
    "image_sets_partitioner = ImageSetsPartitioner().initialise(image_data_param)\n",
    "image_reader = ImageReader().initialise(image_data_param, grouping_param, file_list=image_sets_partitioner.all_files)\n",
    "preprocessing = Preprocessing(net_param, action_param, task_param)\n",
    "normalisation_layers = preprocessing.prepare_normalisation_layers()\n",
    "augmentation_layers = preprocessing.prepare_augmentation_layers()\n",
    "image_reader.add_preprocessing_layers(normalisation_layers + augmentation_layers)\n",
    "\n",
    "csv_reader = CSVReader(('label', 'features')).initialise(csv_data_param,\n",
    "                                                         {'label': (['label']), 'features': (['features'])},\n",
    "                                                         file_list=image_sets_partitioner.all_files)\n",
    "\n",
    "\n",
    "print('One sample from the csv_reader:', np.squeeze(csv_reader(idx=13)[1]['label']))\n",
    "window_sizes = {'image': (100, 100, 1), 'label': (1, 1, 1)}\n",
    "sampler = ResizeSampler(reader=image_reader,\n",
    "                        csv_reader=csv_reader,\n",
    "                        window_sizes=window_sizes,\n",
    "                        num_threads=2,\n",
    "                        smaller_final_batch_mode='drop',\n",
    "                        batch_size=2,\n",
    "                        queue_length=2)\n",
    "sample = next(sampler())\n",
    "print(sample['image'].shape)\n",
    "print(sample['label'].shape)\n",
    "print(sample['features'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
