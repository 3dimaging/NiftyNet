import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.python.data.util import nest

from niftynet.layer.base_layer import Layer
from niftynet.io.image_reader import param_to_dict
from niftynet.io.image_sets_partitioner import ImageSetsPartitioner

class CSVReader(Layer):
    
    def __init__(self, name=None):
        self.name = name
        self._paths = None
        self._labels = None
        self._df = None
        self.label_names = None
        self.dims = None
        
        super(CSVReader, self).__init__(name='csv_reader')
    
    def initialise(self, data_param, task_param=None, file_list=None):
        """
        this function takes in a data_param specifying the name of the source and the location of
        the csv data. Three input modes are supported:
        - 'label' - expects a csv with header subject_id,label.
        - 'features' - expects a csv with header subject_id,<name of feature 1>,<name of feature 2>
        - 'coords' expects a csv with subject_id,x_0,y_0,x_1,y_1
        e.g.::

             data_param = {'label': {'csv_data_file': 'path/to/some_data.csv', 'to_ohe': False}}
             
        :param data_param: dictionary of input sections
        :param task_param: str
        :param file_list: a dataframe generated by ImagePartitioner
            for cross validation, so
            that the reader only loads files in training/inference phases.

        
        """
        self.data_param = data_param
        self.task_param = task_param
        self._path_to_csv = data_param[task_param].get('csv_data_file', None)
        self._to_ohe = data_param[task_param].get('to_ohe', False)
        assert isinstance(self._path_to_csv, str)
        
        self._dims = None
        self.lol = np.nan
        self._indexable_output = None
        self._non_indexable_output = None
        self.file_list = file_list
        self._df = self._parse_csv()
        
        assert file_list is not None
            
        self.num_rows = len(self._df)
        self._paths = self._df['subject_id'].values
        return self
    
    def _parse_csv(self):
        tf.logging.warning('This method will read your entire csv into memory')
        df = pd.read_csv(self._path_to_csv)
        if df.columns[0] != 'subject_id' and len(df.columns) >= 2:
            tf.logging.fatal(
                "The first column of the csv should be called 'subject_id' and there should be at least 2 columns"
            )
        df.index = df['subject_id']
        df = df.loc[self.file_list['subject_id'].values]
        if self._to_ohe and len(df.columns[1:])==1:
            self._dims = len(list(df[df.columns[1]].unique()))
            self._indexable_output = self.to_ohe(df['label'].values)
            return df
        elif not self._to_ohe:
            self._mode = 'features'
            self._dims = len(df.columns[1:])
            self._indexable_output = df.iloc[:, 1:].values
            return df
        else:
            tf.logging.fatal('Unrecognised input format for {}'.format(self.path_to_csv))
    
    def to_ohe(self, labels):
        label_names = list(set(labels))
        return [np.eye(self._dims)[label_names.index(label)] for label in labels]
    
    def layer_op(self, idx=None, shuffle=True):
        if idx is None:
            idx = np.random.randint(len(self.num_rows))
        if self._indexable_output is not None:
            data = self._indexable_output[idx]
            while len(data.shape) < 5:
                data = np.expand_dims(data, -1)
            output_dict = {self.task_param: np.expand_dims(data, 0)}
            return idx, output_dict, None
        else:
            raise Exception('Invalid mode')
    
    @property
    def shapes(self):
        """
        :return: dict of label shape and label location shape
        """
        self._shapes = {self.task_param: (1, self._dims, 1, 1, 1, 1), self.task_param + '_location': (1, 7)}
        print(self._shapes)
        return self._shapes
    
    @property
    def tf_dtypes(self):
        """
        Infer input data dtypes in TF
        """
        self._dtypes = {self.task_param: tf.float32, self.task_param + '_location': tf.int32}
        print(self._dtypes)
        return self._dtypes
    
    @property
    def tf_shapes(self):
        """
        :return: a dictionary of sampler output tensor shapes
        """
        output_shapes = nest.map_structure_up_to(
            self.tf_dtypes, tf.TensorShape, self.shapes)
        return output_shapes